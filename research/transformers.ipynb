{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.14.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/96/06/4beb652c0fe16834032e54f0956443d4cc797fe645527acee59e7deaa0a2/PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-macosx_10_11_x86_64.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, safetensors, pyyaml, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 pyyaml-6.0.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/pranaymishra/anaconda3/envs/Edufy/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "def generate_summary(text, max_length=100):\n",
    "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "def generate_mcqs(summary, num_questions=5):\n",
    "    # Here, you can implement a rule-based approach to generate MCQs based on the summary.\n",
    "    # For simplicity, let's assume a basic pattern for MCQs generation.\n",
    "    questions = []\n",
    "    for i in range(num_questions):\n",
    "        question = f\"What does the passage say about {summary.split()[i]}?\"\n",
    "        options = [\"It is related to the topic.\", \"It is not mentioned in the passage.\"]\n",
    "        questions.append((question, options))\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 1.63G/1.63G [16:24<00:00, 1.65MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 363/363 [00:00<00:00, 498kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Today's video is a cheat sheet which I have made for you. If you have a python or a python program, you can use it for your phone. In this cheat sheet, many times I am making this in the market.\n",
      "\n",
      "Generated MCQs:\n",
      "1. What does the passage say about Today's?\n",
      "   1. It is related to the topic.\n",
      "   2. It is not mentioned in the passage.\n",
      "2. What does the passage say about video?\n",
      "   1. It is related to the topic.\n",
      "   2. It is not mentioned in the passage.\n",
      "3. What does the passage say about is?\n",
      "   1. It is related to the topic.\n",
      "   2. It is not mentioned in the passage.\n",
      "4. What does the passage say about a?\n",
      "   1. It is related to the topic.\n",
      "   2. It is not mentioned in the passage.\n",
      "5. What does the passage say about cheat?\n",
      "   1. It is related to the topic.\n",
      "   2. It is not mentioned in the passage.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"\"\"\n",
    "    Today's video I am going to show you a cheat sheet which I have made for you. If you have a python or a python program, you can use it for your phone. If you have a cheat sheet, you can see that you have seen this in the series of series of syndicats. And in this cheat sheet, many times I am making this in the market. And I have improved the idea of making this in the market. For example, you can see that you can show how to make a print. You can also use it for input functions. Dish, SKF sequels, characters, layers, strings, etc. And this method which you will use in this video is the most useful for you. I am going to add a cheat sheet. If you are using a tap, you can use a top-culture and copy based on your online ID. You can practice python practice. You can see that you have seen a cheat sheet. If you use a VS code like source co-reddit, I am going to add a cheat sheet. Which method do you want to add? But what is the point? Which method do we use? If someone doesn't exist, this is a fine note. You see that this cheat sheet is a good one. You have a lot of ideas on this. I hope that you will be able to use helpful zeroosavith. And if you have any feedback, you can tell me about the common section. You can tell that you can use a cheat sheet with a cheat sheet. You can add a cheat sheet with a cheat sheet. What is the problem? Because it is better than the cheat sheet. I am going to demonstrate the step. So, all the cheat sheets I know are not important. And plan is that I am a bad one. I am going to use a cheat sheet with all my good things. Because this is a good one. I am very bad. It is a very bad one. You have to keep your cheat sheet in one language. You are coding and coding and you are directly here. All of you are using a cheat sheet. I have many helpful things. So, I have a playlist on which cheat sheet you need to do. You have to access it. I have to go to HTML and go to JavaScript and show you. But if you are not interested in it, then watch this video. You should also see the cheat sheet here. You will see that there are many helpful things in it. Any updates will be shown. Changes will be updated on the cheat sheet. You have to take care of your print out. You have to pay for the video from this. You can also follow the video on the control P. You can also see the video on the same as video. And if you want to see it, you can also follow it. You can also follow it on the other side. See you in the next video. Thank you so much guys. Watch this video and I will see you next time.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    summary = generate_summary(input_text)\n",
    "    mcqs = generate_mcqs(summary)\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    print(summary)\n",
    "    print(\"\\nGenerated MCQs:\")\n",
    "    for idx, (question, options) in enumerate(mcqs, 1):\n",
    "        print(f\"{idx}. {question}\")\n",
    "        for i, option in enumerate(options, 1):\n",
    "            print(f\"   {i}. {option}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT SUMMARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer , BartForConditionalGeneration, BartConfig\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 953kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 658kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.72k/1.72k [00:00<00:00, 8.89MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('transcription.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello friends and welcome to another video tutorial by Geeksorgames. In this video we will see how to search in an almost sorted element. Problem statement. Given an array which is sorted but after sorting some elements are moved to either of the adjacent positions, that is, Iat element of an array may be present at index i plus 1 or i minus 1. We need to write an efficient function to search an element in this array. The array shown here is almost sorted because 4 and 10 have moved to their adjacent positions but other than that all elements are in their correct position. For example, if this is the given array and we need to search the index of 40, the output will be 2 because 40 is presented in index 2. In cases like this where the key is not present in this array, output should be minus 1. Now, the most of the solution is to linearly search the key in the given array. Time complexity of the solution would be big of n but we can also modify binary search to do it in log n time. The idea is to compare the key with the middle three elements because the actual middle element could be present at mid minus 1 or mid plus 1 position 2. If the key is present in one of these three positions, then return the index. If not, then compare the key with the middle element and decide better to go in the left half or right half. Comparing with the middle element is enough as all the elements after mid plus 2 would be greater than the middle element and all the elements before mid minus 2 would be smaller than the middle element. Let\\'s try and just standing the code now. Starting with the main function. This is the initial array and 4 is the element to be searched. We call binary search on the complete array. Now let\\'s look at the function. We enter this if condition now. Mets towards the index of the middle most element of the array. Now we check if the key is present in either of the positions mid, mid minus 1 or mid plus 1. If so, then we return the index. If the key is smaller than the middle element, we call binary search on the left half. And if the key is bigger than the middle element, we call binary search on the right half. Minus 1 is returned in the case where the element is not present in the array. Then in the main function, the return value gets printed. Let\\'s look at a working example based on the binary search approach. This is the initial array and we need to find the index of 70. First, binary search is called on the entire array. L is 0 and R is 6 here. Mets turns out to be 3. Now we compare the key with mid, mid minus 1, and mid plus 1 element. And it turns out that none of them is equal to key. We now compare the key with the middle element. Since key is greater than the middle element which was 20. We call binary search on the right half. L is 5 and R is 6 now. Mid becomes 5. Now, element at mid is not equal to the key, but the element at mid plus 1, which is 70, is equal to R key. So we return mid plus 1, that is 6. And hence the output is 6. Thank you for watching the video. Please leave us your comments.\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICAL_TO_SUMARRY = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([ARTICAL_TO_SUMARRY], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(inputs['input_ids'], max_length=1000, early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0,  1121,    42,   569,    52,    40,   192,   141,     7,\n",
       "          1707,    11,    41,   818, 24713,  7510,     4,  6211,    41,  8932,\n",
       "            61,    16, 24713,    53,    71, 28662,   103,  4785,    32,  1410,\n",
       "             7,  1169,     9,     5, 12142,  2452,     6,    14,    16,     6,\n",
       "            38,   415,  7510,     9,    41,  8932,   189,    28,  1455,    23,\n",
       "          1965,   939,  2704,   112,    50,   939, 10877,   112,     4,   166,\n",
       "           240,     7,  3116,    41,  5693,  5043,     7,  1707,    41,  7510,\n",
       "            11,    42,  8932,     4,  3421, 13879,     9,     5,  2472,    74,\n",
       "            28,   380,     9,   295,    53,    52,    64,    67, 23209, 32771,\n",
       "          1707,     7,   109,    24,    11,  7425,   295,    86,     4,    20,\n",
       "          1114,    16,     7,  8933,     5,   762,    19,     5,  1692,   130,\n",
       "          4785,     4,   318,     5,   762,    16,  1455,    11,    65,     9,\n",
       "           209,   130,  2452,     6,   172,   671,     5,  1965,     4,     2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFinal = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In this video we will see how to search in an almost sorted element. Given an array which is sorted but after sorting some elements are moved to either of the adjacent positions, that is, Iat element of an array may be present at index i plus 1 or i minus 1. We need to write an efficient function to search an element in this array. Time complexity of the solution would be big of n but we can also modify binary search to do it in log n time. The idea is to compare the key with the middle three elements. If the key is present in one of these three positions, then return the index.']\n"
     ]
    }
   ],
   "source": [
    "print(textFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Edufy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
